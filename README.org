#+title: Readme
* Requirements
- Julia ver 1.11.0 (2024-10-07)
* About this program
This is a multi-armed bandit problems simulator that is designed for machine learning simulations (algorithm evaluation), as well as cognitive scientific analysis (parameter and model estimation and data fit).
#+begin_src sh
julia -p 4 bandit1.jl
#+end_src
will show some result.
* The design
Usually, a reinforcement learning system (with a single state) consists of a pair of agent and environment:
#+begin_src ascii
#########            #########
#       # --action-> #       #
# agent #            #  env  #
#       # <-reward-- #       #
#########            #########
#+end_src
In this program, a System consists of Agent and Environment.
Agent has a Policy (such as epsilon-greedy method) and a ActionValueEstimator (such as Q-values with the learning parameter α).
The information such as action taken and reward issued in the System is recorded in a History.
The History can have an Evaluation that calculates the performance of the Agent in relation to the Environment.

The separation of Agent into a policy and an estimator enabled
combinations of them, such as Softmax with Q-values and Softmax with
sample average estimator. 
* To-do
- Implementation of RS, Softsatisficing and more descriptive satisficing models.
  - RS can be used with Q-values, not just with the average reward estimator, which could even make the likelihoood analysis smoother.
- Parameter recovery analysis, and how to implement it into the current design.
- Data fit with the actual bandit problem experiment data.
* A Mermaid diagram
#+begin_src mermaid
classDiagram
    class AbstractActionValueEstimator {
        <<abstract>>
    }
    class SampleAverageEstimator {
        +Q: Vector{Float64}
        +N: Vector{Int}
    }
    class QEstimator {
        +Q: Vector{Float64}
        +α: Float64
    }
    class DLREstimator {
        +Q: Vector{Float64}
        +αp: Float64
        +αn: Float64
    }
    class ThompsonSamplingEstimator {
        +alpha: Vector{Float64}
        +beta: Vector{Float64}
    }

    class AbstractPolicy {
        <<abstract>>
    }
    class EpsilonGreedyPolicy {
        +ϵ: Float64
    }
    class SoftmaxPolicy {
        +β: Float64
    }
    class UCBPolicy {
        +c: Float64
        +t: Int
    }
    class UCBTunedPolicy {
        +t: Int
        +sum_of_squares: Vector{Float64}
    }
    class SatisficingPolicy {
        +aspiration_level: Float64
    }
    class ThompsonSamplingPolicy

    class AbstractEnvironment {
        <<abstract>>
    }
    class Environment {
        +n_arms: Int
        +distributions: AbstractVector{Distribution{Univariate}}
    }

    class AbstractHistory {
        <<abstract>>
    }
    class History {
        +actions: Vector{Int}
        +expectations: Vector{Vector{Float64}}
        +rewards: Vector{Float64}
    }
    class HistoryRich {
        +actions: Vector{Int}
        +expectations: Vector{Vector{Float64}}
        +rewards: Vector{Float64}
        +values: Vector{Vector{Float64}}
    }

    class AbstractSystem {
        <<abstract>>
    }
    class System {
        +agent: Agent
        +env: Environment
        +history: AbstractHistory
        +rng: AbstractRNG
    }
    class SystemRich {
        +agent: Agent
        +env: Environment
        +history: AbstractHistory
        +rng: AbstractRNG
    }

    class Agent {
        +estimator: AbstractActionValueEstimator
        +policy: AbstractPolicy
    }

    AbstractActionValueEstimator <|-- SampleAverageEstimator
    AbstractActionValueEstimator <|-- QEstimator
    AbstractActionValueEstimator <|-- DLREstimator
    AbstractActionValueEstimator <|-- ThompsonSamplingEstimator

    AbstractPolicy <|-- EpsilonGreedyPolicy
    AbstractPolicy <|-- SoftmaxPolicy
    AbstractPolicy <|-- UCBPolicy
    AbstractPolicy <|-- UCBTunedPolicy
    AbstractPolicy <|-- SatisficingPolicy
    AbstractPolicy <|-- ThompsonSamplingPolicy

    AbstractEnvironment <|-- Environment

    AbstractHistory <|-- History
    AbstractHistory <|-- HistoryRich

    AbstractSystem <|-- System
    AbstractSystem <|-- SystemRich

    Agent --> AbstractActionValueEstimator
    Agent --> AbstractPolicy
    System --> Agent
    System --> Environment
    System --> AbstractHistory
    SystemRich --> Agent
    SystemRich --> Environment
    SystemRich --> AbstractHistory
#+end_src
